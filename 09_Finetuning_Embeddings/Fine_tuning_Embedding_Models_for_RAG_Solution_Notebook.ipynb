{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ckbbj5diaHkg"
      },
      "source": [
        "# Fine-tuning Embeddings for RAG on Specific Data - HARD MODE\n",
        "\n",
        "As we start our \"fine-tuning\" week, we'll start with the lowest hanging improvement one can do for RAG - which is:\n",
        "\n",
        "Fine-tuning embeddings!\n",
        "\n",
        "- 🤝 Breakout Room #1:\n",
        "  - Task 1: Dependencies and Boilerplate\n",
        "  - Task 2: Loading Data\n",
        "  - Task 3: Constructing a Fine-tuning Dataset\n",
        "  - Task 4: Fine-tuning `snowflake-arctic-embed-l`\n",
        "  - Task 5: Evaluating our Retriever\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xwor_3X6ODX"
      },
      "source": [
        "#### Basic Overview of Fine-tuning Embeddings\n",
        "\n",
        "In essence, what we want to do when we fine-tune our embedding models is very simple:\n",
        "\n",
        "```\n",
        "Move the embeddings for questions relating to a document\n",
        "closer together with that document\n",
        "```\n",
        "\n",
        "We can think of fine-tuning our embedding models as follows:\n",
        "\n",
        "1) We have some pair of text items that *should* be closer together\n",
        "  - `Question`, `Document` pairs\n",
        "  - EX: `Who drives the bus?`, `The bus was driven by Kyle, the Bus Driver`.\n",
        "\n",
        "2) We use these pairs as labeled data to fine-tune our embedding model.\n",
        "\n",
        "The process of training helps the model more accurately associate our questions with the correct documents."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DX5R3HVz6FOQ"
      },
      "source": [
        "#####❓ Question #1:\n",
        "\n",
        "Describe the nuance between using Q&D pairs to train the embedding model vs. inter-document pairs/related sentences.\n",
        "\n",
        "What caveats does this approach have? Are there any special considerations for what kind of Q's we should use?\n",
        "\n",
        "---\n",
        "\n",
        "**ANSWER:**\n",
        "\n",
        "We are specifically relating *the questions* to *the documents*. This means that we are making our embedding model at the very specific task of relating potential questions to specific documents.\n",
        "\n",
        "There are many caveats, but the main ones are:\n",
        "\n",
        "- Your Q's should reflect the Q's of your users\n",
        "- This kind of fine-tuning will (purposefully) \"overfit\" on your data; this is the desired result in this case."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-NkSaurzbpyS"
      },
      "source": [
        "## Task 1: Dependencies and Boilerplate\n",
        "\n",
        "We'll set up our `nest_asyncio` so we can leverage async loops in our Notebook.\n",
        "\n",
        "We'll also install the required libraries we'll be using today, and set up our OpenAI API key!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9c_EUibmcDU3"
      },
      "source": [
        "### Nest Asyncio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "zq-6s7LbPnKH"
      },
      "outputs": [],
      "source": [
        "import nest_asyncio\n",
        "\n",
        "nest_asyncio.apply()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R8uFz8RVcFFu"
      },
      "source": [
        "### Install Dependencies\n",
        "\n",
        ">> NOTE: You do not need to do these steps if you are running this notebook locally with `uv`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ulZIBA1ZoSsV",
        "outputId": "12d9c766-843f-40bf-bdf8-e0ed04b6d87f"
      },
      "outputs": [],
      "source": [
        "#!pip install -qU langchain_openai langchain_huggingface langchain_core langchain langchain_community langchain-text-splitters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "3GFD7B-tOCrx"
      },
      "outputs": [],
      "source": [
        "#!pip install -qU faiss-cpu python-pptx==1.0.2 nltk==3.9.1 pymupdf beautifulsoup4 lxml "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0FM-eUlrcI8a"
      },
      "source": [
        "### Provide OpenAI API Key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wA_mlurVqtrp",
        "outputId": "18cccb1e-095f-40fa-def5-2454f9bcdcae"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import getpass\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter Your OpenAI API Key: \")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TFZ217gCDVTr"
      },
      "source": [
        "## Task 2: Loading Data\n",
        "\n",
        "We'll prepare our data - and download our webpages which we'll be using for our data today.\n",
        "\n",
        "These webpages are from [Simon Willison's](https://simonwillison.net/) yearly \"AI learnings\".\n",
        "\n",
        "- [2023 Blog](https://simonwillison.net/2023/Dec/31/ai-in-2023/)\n",
        "- [2024 Blog](https://simonwillison.net/2024/Dec/31/llms-in-2024/)\n",
        "\n",
        "Let's start by collecting our data into a useful pile!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mkdir: data_hard: File exists\n"
          ]
        }
      ],
      "source": [
        "!mkdir data_hard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  293k    0  293k    0     0   102k      0 --:--:--  0:00:02 --:--:--  102k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  359k    0  359k    0     0   169k      0 --:--:--  0:00:02 --:--:--  169k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  475k    0  475k    0     0   108k      0 --:--:--  0:00:04 --:--:--  118k\n"
          ]
        }
      ],
      "source": [
        "!curl https://www.mrmoneymustache.com/2012/01/13/the-shockingly-simple-math-behind-early-retirement/ -o data_hard/the-shockingly-simple-math-behind-early-retirement.html\n",
        "!curl https://www.mrmoneymustache.com/2012/05/29/how-much-do-i-need-for-retirement/ -o data_hard/how-much-do-i-need-for-retirement.html\n",
        "!curl https://www.mrmoneymustache.com/2012/03/29/killing-your-1000-grocery-bill/ -o data_hard/killing-your-1000-grocery-bill.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "DHJhTzsvN75t"
      },
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders import DirectoryLoader\n",
        "from langchain_community.document_loaders import BSHTMLLoader\n",
        "\n",
        "path = \"data_hard/\"\n",
        "text_loader = DirectoryLoader(path, glob=\"*.html\", loader_cls=BSHTMLLoader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-UbKa6-V0nvp"
      },
      "source": [
        "Next, we'll set up a classic naive chunking strategy as we only care that the documents get parsed into chunks that we can generate synthetic questions about."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "NsPrOOqXOsNX"
      },
      "outputs": [],
      "source": [
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size = 750,\n",
        "    chunk_overlap  = 20,\n",
        "    length_function = len\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lf_PoX7l09Rg"
      },
      "source": [
        "Next we can load/split these documents as follows.\n",
        "\n",
        ">> NOTE: You may need to run this cell twice to get it to work."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "OMYPX6N6Os8M"
      },
      "outputs": [],
      "source": [
        "training_documents = text_splitter.split_documents(text_loader.load())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PAozuMoNOvnp",
        "outputId": "dc1d663e-7153-4c51-cedb-d1bc3888c4ae"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "765"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(training_documents)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0yE2TFIq1BuJ"
      },
      "source": [
        "Next, we're going to associate each of our chunks with a unique identifier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "AwyIForybIpo"
      },
      "outputs": [],
      "source": [
        "import uuid\n",
        "\n",
        "id_set = set()\n",
        "\n",
        "for document in training_documents:\n",
        "  id = str(uuid.uuid4())\n",
        "  while id in id_set:\n",
        "    id = uuid.uuid4()\n",
        "  id_set.add(id)\n",
        "  document.metadata[\"id\"] = id"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PJnL4oNg341U"
      },
      "source": [
        "Next, we'll simply use naive Python slicing to create a training, test, and validation set to prepare our data for the next step."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "MTS4GTSEcnG4"
      },
      "outputs": [],
      "source": [
        "# Calculate the indices for slicing\n",
        "train_end = int(len(training_documents) * 0.76)\n",
        "val_end = train_end + int(len(training_documents) * 0.12)\n",
        "\n",
        "# Slice the data\n",
        "training_split_documents = training_documents[:train_end]\n",
        "val_split_documents = training_documents[train_end:val_end]\n",
        "test_split_documents = training_documents[val_end:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzlvKbONDWvQ"
      },
      "source": [
        "## [HARD-MODE] Task 3a: Constructing a Fine-tuning Dataset - Naive Approach\n",
        "\n",
        "Using the nodes we created above, we can finally start constructing a fine-tuning dataset utilizing OpenAI's `gpt-4o-mini` (released [today](https://openai.com/index/gpt-4o-mini-advancing-cost-efficient-intelligence/)).\n",
        "\n",
        "The basic idea here is straightforward enough:\n",
        "\n",
        "1. We look at a document\n",
        "2. We generate questions that could be answered by that node\n",
        "\n",
        "This gives us a number of question/context pairs that we can use to fine-tune our Embeddings model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "_EWfmIscMrvg"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "qa_chat_model = ChatOpenAI(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    temperature=0\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-hLnsSB6Y-S"
      },
      "source": [
        "We'll create a simple Question Generation prompt to query `gpt-4o-mini` to generate Questions for each retrieved context."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "diEWcw00NMSj"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "qa_prompt = \"\"\"\\\n",
        "Given the following context, you must generate questions based on only the provided context.\n",
        "\n",
        "You are to generate {n_questions} questions which should be provided in the following format:\n",
        "\n",
        "1. QUESTION #1\n",
        "2. QUESTION #2\n",
        "...\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\"\"\"\n",
        "\n",
        "qa_prompt_template = ChatPromptTemplate.from_template(qa_prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u87Izpgm6_fk"
      },
      "source": [
        "We'll create a simple chain to query the LLM!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "ggl9SSjiNbpG"
      },
      "outputs": [],
      "source": [
        "question_generation_chain = qa_prompt_template | qa_chat_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4duvHirh7DQv"
      },
      "source": [
        "There's a lot going on in this function - let's take a deeper look:\n",
        "\n",
        "1. First, we provide a list of documents and a number of questions\n",
        "2. We, for each document in our list, generate `n_questions` of questions.\n",
        "3. We then associate those questions and contexts via a `UUID`.\n",
        "\n",
        "> NOTE: The reason we're doing this `UUID` association is for ease of use later in the notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Lm2JvgC9X37"
      },
      "source": [
        "##### 🏗️ Activity #1:\n",
        "\n",
        "We have:\n",
        "\n",
        "- Lists of `Documents` with the `metadata` field `id`.\n",
        "\n",
        "We need:\n",
        "\n",
        "- An object with key `id`, which have values `str` questions.\n",
        "- An object with key `question_id`, which have values `List(str)` which will be a list of associated `context_id`.\n",
        "\n",
        "An Example:\n",
        "\n",
        "question_object:\n",
        "```python\n",
        "{\n",
        "'b4b95fb6-f827-4454-aa5b-20e62733f172': 'What types of accessible formats are available for persons with disabilities?',\n",
        "'df58ee4f-714c-419e-8324-94e5870574e2': 'How do accessible formats benefit persons with disabilities?',\n",
        "'505fce8b-0e56-48de-a251-61027e396918': 'What are some of the risks associated with the increasing capabilities of AI systems that generate synthetic content?',\n",
        "'8ff0ab33-60dc-4fee-8958-91bfb686aca8': 'Why is it important for providers of AI systems to embed technical solutions for marking and detecting synthetic content?'\n",
        "}\n",
        " ```\n",
        "\n",
        " context_object:\n",
        " ```python\n",
        "{\n",
        "'b4b95fb6-f827-4454-aa5b-20e62733f172': ['dd75bf94-75f3-4603-8e4b-5522f6925638'],\n",
        "'df58ee4f-714c-419e-8324-94e5870574e2': ['dd75bf94-75f3-4603-8e4b-5522f6925638'],\n",
        "'505fce8b-0e56-48de-a251-61027e396918': ['ffe3893f-688c-48e8-90bd-7a9feb953d90'],\n",
        "'8ff0ab33-60dc-4fee-8958-91bfb686aca8': ['ffe3893f-688c-48e8-90bd-7a9feb953d90'],\n",
        "}\n",
        " ```\n",
        "\n",
        " As you can see, a piece of context can be associated with more than 1 question.\n",
        "\n",
        " The task is to write the Python function(s) to accomplish this task.\n",
        "\n",
        " Your function signature is provided below, along with the desired return values.\n",
        "\n",
        " > NOTE: You can make any modifications that you desire - assuming that you have the correct input and outputs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "U4yi4NfTCnLc"
      },
      "outputs": [],
      "source": [
        "import tqdm\n",
        "import uuid\n",
        "import re\n",
        "\n",
        "async def create_questions(documents, n_questions):\n",
        "  questions = {}\n",
        "  relevant_docs = {}\n",
        "\n",
        "  ### YOUR CODE HERE\n",
        "  for document in tqdm.tqdm(documents, desc=\"Processing documents\"):\n",
        "        doc_id = document.metadata[\"id\"]\n",
        "        context = document.page_content\n",
        "\n",
        "        # Use question_generation_chain to generate questions on the chunks\n",
        "        question_generation_result = await question_generation_chain.ainvoke({\n",
        "            \"context\":context,\n",
        "            \"n_questions\":n_questions\n",
        "        })\n",
        "\n",
        "        for question in question_generation_result.content.split('\\n'):\n",
        "            # Strip question\n",
        "            question = re.sub(r\"^\\d+\\.\", \"\", question).strip()\n",
        "            \n",
        "            # Associate doc with question by id in return value objects\n",
        "            q_id = str(uuid.uuid4())\n",
        "            questions[q_id] = question\n",
        "            relevant_docs[q_id] = [doc_id]\n",
        "\n",
        "  return questions, relevant_docs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5W0eWOUo4QGL"
      },
      "source": [
        "### REMOVE `await` IF NOT USING ASYNC (HINT: Use `async`)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "85Dq6KRqEs0F",
        "outputId": "60dcd580-b6e8-4e3b-d605-05b492ca5c96"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing documents: 100%|██████████| 581/581 [13:23<00:00,  1.38s/it]  \n"
          ]
        }
      ],
      "source": [
        "training_questions, training_relevant_contexts = await create_questions(training_split_documents, 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_FSTG0bb7w73"
      },
      "source": [
        "We'll use the function to generate training, validation, and test data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eIZm4CqGVzBx",
        "outputId": "65a7703a-c528-40f6-aff4-1be84902cfc4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing documents: 100%|██████████| 91/91 [02:10<00:00,  1.44s/it]\n"
          ]
        }
      ],
      "source": [
        "val_questions, val_relevant_contexts = await create_questions(val_split_documents, 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o6qUHg9sV2_y",
        "outputId": "b03bf5c6-d392-40bf-a061-1daceba2962e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing documents: 100%|██████████| 93/93 [01:46<00:00,  1.14s/it]\n"
          ]
        }
      ],
      "source": [
        "test_questions, test_relevant_contexts = await create_questions(test_split_documents, 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_jYOnAI43zK"
      },
      "source": [
        "### Reformating and Saving Datasets\n",
        "\n",
        "Now, we can save our datasets for later use!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "iF6IFFq9VsNu"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "training_corpus = {train_item.metadata[\"id\"] : train_item.page_content for train_item in training_split_documents}\n",
        "\n",
        "train_dataset = {\n",
        "    \"questions\" : training_questions,\n",
        "    \"relevant_contexts\" : training_relevant_contexts,\n",
        "    \"corpus\" : training_corpus\n",
        "}\n",
        "\n",
        "with open(\"data_hard/training_dataset.jsonl\", \"w\") as f:\n",
        "  json.dump(train_dataset, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "PqF9WaueV-V8"
      },
      "outputs": [],
      "source": [
        "val_corpus = {val_item.metadata[\"id\"] : val_item.page_content for val_item in val_split_documents}\n",
        "\n",
        "val_dataset = {\n",
        "    \"questions\" : val_questions,\n",
        "    \"relevant_contexts\" : val_relevant_contexts,\n",
        "    \"corpus\" : val_corpus\n",
        "}\n",
        "\n",
        "with open(\"data_hard/val_dataset.jsonl\", \"w\") as f:\n",
        "  json.dump(val_dataset, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "0DSQ7WMnWAu6"
      },
      "outputs": [],
      "source": [
        "train_corpus = {test_item.metadata[\"id\"] : test_item.page_content for test_item in test_split_documents}\n",
        "\n",
        "test_dataset = {\n",
        "    \"questions\" : test_questions,\n",
        "    \"relevant_contexts\" : test_relevant_contexts,\n",
        "    \"corpus\" : train_corpus\n",
        "}\n",
        "\n",
        "with open(\"data_hard/test_dataset.jsonl\", \"w\") as f:\n",
        "  json.dump(test_dataset, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## [HARD-MODE] Task 3b: Constructing a Fine-tuning Dataset - RAGAS Knowledge Graph Approach"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "os.environ[\"RAGAS_APP_TOKEN\"] = getpass.getpass(\"Please enter your Ragas API key!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ragas.llms import LangchainLLMWrapper\n",
        "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "generator_llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4o-mini\"))\n",
        "generator_embeddings = LangchainEmbeddingsWrapper(OpenAIEmbeddings())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Persona(name='Fiduciary', role_description='You are an expert in personal and family finance who speaks in the best interest of others'),\n",
              " Persona(name='FIRE', role_description='You have achieved financial independence and have retired early, simply by mastering the fundamentals of personal finance'),\n",
              " Persona(name='Worker', role_description='You are a hard worker, who one day hopes to be financially independent and retire early')]"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from ragas.testset.persona import Persona\n",
        "\n",
        "persona_fiduciary = Persona(\n",
        "    name = \"Fiduciary\",\n",
        "    role_description = \"You are an expert in personal and family finance who speaks in the best interest of others\",\n",
        ")\n",
        "\n",
        "persona_fire = Persona(\n",
        "    name = \"FIRE\",\n",
        "    role_description = \"You have achieved financial independence and have retired early, simply by mastering the fundamentals of personal finance\",\n",
        ")\n",
        "\n",
        "persona_worker = Persona(\n",
        "    name = \"Worker\",\n",
        "    role_description = \"You are a hard worker, who one day hopes to be financially independent and retire early\",\n",
        ")\n",
        "\n",
        "persona_list = [persona_fiduciary, persona_fire, persona_worker]\n",
        "persona_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ragas.testset import TestsetGenerator\n",
        "\n",
        "generator = TestsetGenerator(llm=generator_llm, embedding_model=generator_embeddings,persona_list=persona_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ragas.testset.synthesizers import default_query_distribution, SingleHopSpecificQuerySynthesizer, MultiHopAbstractQuerySynthesizer, MultiHopSpecificQuerySynthesizer\n",
        "\n",
        "query_distribution = [\n",
        "        (SingleHopSpecificQuerySynthesizer(llm=generator_llm), 1),\n",
        "        \n",
        "        #multi hops were not working for me - seeing \"No clusters found in the knowledge graph. Try changing the relationship condition.\"\n",
        "        #(MultiHopAbstractQuerySynthesizer(llm=generator_llm), 0),\n",
        "        #(MultiHopSpecificQuerySynthesizer(llm=generator_llm), 0),\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e006315309c248b9a28e9e0f906011aa",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying SummaryExtractor:   0%|          | 0/453 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7eb347c3fe8a45bf95de9192b7307834",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying CustomNodeFilter:   0%|          | 0/581 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Node 005ca84a-a5e2-438d-9bd4-780909d777e6 does not have a summary. Skipping filtering.\n",
            "Node 401c9b16-b9b6-490f-95ae-e0e7d6d7a952 does not have a summary. Skipping filtering.\n",
            "Node 984b76e9-91ea-494a-b3d9-324759bf0e79 does not have a summary. Skipping filtering.\n",
            "Node 659ea6c4-c892-4cdf-afd6-59e4f0c2477a does not have a summary. Skipping filtering.\n",
            "Node 6774a6fd-5afa-460d-9242-2dcf893ef117 does not have a summary. Skipping filtering.\n",
            "Node c0495fbf-e295-491e-ac69-1551fb0eeef6 does not have a summary. Skipping filtering.\n",
            "Node 5e7f6b5c-1e2c-4f87-913a-6df0cabf2889 does not have a summary. Skipping filtering.\n",
            "Node 47d16392-d478-43ac-be74-146bdcbd0942 does not have a summary. Skipping filtering.\n",
            "Node 5155a824-6630-4259-952b-3dea95457c8c does not have a summary. Skipping filtering.\n",
            "Node 9951e7b0-36dd-43c1-b511-b5c586e39471 does not have a summary. Skipping filtering.\n",
            "Node 5aade670-db32-4008-83e6-0a27b9a227d8 does not have a summary. Skipping filtering.\n",
            "Node 26582e64-b5e1-4db4-8fb5-fce670159c35 does not have a summary. Skipping filtering.\n",
            "Node d2264a99-fe68-4577-af9a-75e672cd849d does not have a summary. Skipping filtering.\n",
            "Node 17e33006-cbd0-4fd7-bc34-001ba5292b97 does not have a summary. Skipping filtering.\n",
            "Node 7d4b986c-f636-41c3-90d7-283bf52a0ec4 does not have a summary. Skipping filtering.\n",
            "Node ea73d0e6-0d6d-4da3-ba51-3906f1b64808 does not have a summary. Skipping filtering.\n",
            "Node dedccc22-7828-4d74-8a98-d149e6ec77f2 does not have a summary. Skipping filtering.\n",
            "Node 8c94a67a-934f-42d8-b569-430ef5ec6ca8 does not have a summary. Skipping filtering.\n",
            "Node 68a67f50-1b03-4c34-9c68-ccdddd2a415c does not have a summary. Skipping filtering.\n",
            "Node fea3aa11-1993-46e5-9538-bbee07b2d363 does not have a summary. Skipping filtering.\n",
            "Node 83286101-fe6e-4d08-8a7e-ec4ba1ffd1f6 does not have a summary. Skipping filtering.\n",
            "Node f1e3185b-8cf7-4165-9f46-80eea1b034e3 does not have a summary. Skipping filtering.\n",
            "Node 5d84954d-d2b6-43ae-a6cd-b00d9d072a0d does not have a summary. Skipping filtering.\n",
            "Node 2c893075-0c79-4ffe-957a-ecdfb26b2dcd does not have a summary. Skipping filtering.\n",
            "Node c18fd3c0-d568-4ba5-b17c-6f81c47eec41 does not have a summary. Skipping filtering.\n",
            "Node d57cbd25-9674-4322-9941-b4f9eb998ae2 does not have a summary. Skipping filtering.\n",
            "Node af1cd9a6-6be8-4a90-bf0a-7d05daebef96 does not have a summary. Skipping filtering.\n",
            "Node fa6d6943-7fd2-4ecd-99ac-e512f74ee0b1 does not have a summary. Skipping filtering.\n",
            "Node ca568d78-00b9-4daf-83bb-8e6494f64df1 does not have a summary. Skipping filtering.\n",
            "Node f2df42b0-dfe4-48ee-89a9-3667b8de8fd5 does not have a summary. Skipping filtering.\n",
            "Node ce3bb786-2e54-4a52-adf3-3f91f329811c does not have a summary. Skipping filtering.\n",
            "Node b2be68cd-4470-4411-b4cf-c519a95e927b does not have a summary. Skipping filtering.\n",
            "Node 8a03fb08-5ab4-4727-af3d-be96f35a296b does not have a summary. Skipping filtering.\n",
            "Node 4f1a2baa-2767-49d1-b5a4-fc226572b858 does not have a summary. Skipping filtering.\n",
            "Node 7c4f6c30-1175-4931-93b0-2e06f09359d3 does not have a summary. Skipping filtering.\n",
            "Node 9ae5ce66-c5ad-4901-95dd-bd50ae9fc910 does not have a summary. Skipping filtering.\n",
            "Node 25927208-a21e-408d-a7be-2265ee3d7265 does not have a summary. Skipping filtering.\n",
            "Node 96fe04fc-9c3d-495e-9cff-0deaff438787 does not have a summary. Skipping filtering.\n",
            "Node dc3b70c9-7367-48e9-a63a-6f7673bb6fbb does not have a summary. Skipping filtering.\n",
            "Node ef898d98-0de9-4b89-bc1b-3bc2419732d6 does not have a summary. Skipping filtering.\n",
            "Node 8a21bbe5-28a0-408d-a4c3-d640645f0a64 does not have a summary. Skipping filtering.\n",
            "Node 9b9e713f-37ae-4404-af47-6b92929922b3 does not have a summary. Skipping filtering.\n",
            "Node 785c8422-47b7-434e-9aa8-8aafb8a5e792 does not have a summary. Skipping filtering.\n",
            "Node 272908b4-1467-4ffc-bdec-5bfa52efb7d6 does not have a summary. Skipping filtering.\n",
            "Node aa4f1b10-5570-4f40-be08-ebf436cdc0e9 does not have a summary. Skipping filtering.\n",
            "Node a477230a-8fa8-42bf-a708-f111bdcb44b0 does not have a summary. Skipping filtering.\n",
            "Node 99fe4d77-ce96-4bc7-82df-aff4810ccfe8 does not have a summary. Skipping filtering.\n",
            "Node 78d43032-e363-48c9-8538-fafc91bb548c does not have a summary. Skipping filtering.\n",
            "Node 50b729e6-a81d-4cb6-b641-30f1370d412f does not have a summary. Skipping filtering.\n",
            "Node 28dbd23c-cabf-40c2-9682-97b4d191c6c8 does not have a summary. Skipping filtering.\n",
            "Node b8ab57e6-67b2-4eed-aea7-80aaab9656d0 does not have a summary. Skipping filtering.\n",
            "Node 207aa5e3-a182-4493-aebe-7133a3db05d4 does not have a summary. Skipping filtering.\n",
            "Node 2732854c-a64b-49fe-adb2-127db320122d does not have a summary. Skipping filtering.\n",
            "Node 809642e5-85d5-47e7-b516-933ffc693800 does not have a summary. Skipping filtering.\n",
            "Node 9fbc2b9d-9ee4-4adb-9d75-27464c6e251d does not have a summary. Skipping filtering.\n",
            "Node 10381128-6fbb-4b28-ba05-da05b3967c06 does not have a summary. Skipping filtering.\n",
            "Node 7da8a56d-5029-4d92-a9e7-10ed08da8980 does not have a summary. Skipping filtering.\n",
            "Node e8313ac6-1d23-4bf2-93db-9e7f11e5b6bc does not have a summary. Skipping filtering.\n",
            "Node 7f89d82f-c456-4254-a419-82a58afd248c does not have a summary. Skipping filtering.\n",
            "Node 655f2cac-c8a4-4904-915c-f72f78e64da2 does not have a summary. Skipping filtering.\n",
            "Node d5e6ca6c-dea4-4814-b973-b01703ea591b does not have a summary. Skipping filtering.\n",
            "Node faaf44ce-16b9-433f-ae96-7fac0aabed4a does not have a summary. Skipping filtering.\n",
            "Node 0e168ac3-f6ad-46e8-bd60-dd8a028ecaca does not have a summary. Skipping filtering.\n",
            "Node da5e6b4f-1cd5-49f9-b459-261e35037727 does not have a summary. Skipping filtering.\n",
            "Node fd3fca9d-2d1a-4ff7-a865-9157dd371a32 does not have a summary. Skipping filtering.\n",
            "Node 6c2dbf6a-d861-44ba-b57d-0c9bb87b3c46 does not have a summary. Skipping filtering.\n",
            "Node eb75e6e4-749d-4d12-a795-cbd66bff505d does not have a summary. Skipping filtering.\n",
            "Node 0ddfc4f4-5b69-46e4-ba3b-5f5491f982e8 does not have a summary. Skipping filtering.\n",
            "Node efdc2fbc-37b2-47eb-afb3-442af08fb180 does not have a summary. Skipping filtering.\n",
            "Node 08da6fb6-2c44-4d81-9e0a-1446eaf5d824 does not have a summary. Skipping filtering.\n",
            "Node 837a42b2-9216-4be8-a0f4-f540d00a3eef does not have a summary. Skipping filtering.\n",
            "Node 72a859a9-a19f-486d-8cae-1b23f406cd4b does not have a summary. Skipping filtering.\n",
            "Node 46b3c957-1e40-4e2d-9624-c9fca639a46a does not have a summary. Skipping filtering.\n",
            "Node 9bfa869a-3b16-4ae8-b3bd-b5e518ccedec does not have a summary. Skipping filtering.\n",
            "Node a9e60b5e-2992-41c8-aa0d-d1bb6e9cf5e7 does not have a summary. Skipping filtering.\n",
            "Node 24f7ae00-fd4c-4381-a658-dd4d717a52eb does not have a summary. Skipping filtering.\n",
            "Node be363f4d-b22a-45a2-aad8-505fd48305e1 does not have a summary. Skipping filtering.\n",
            "Node 0b1965fb-4e53-40ba-8b68-d56fff5fe94b does not have a summary. Skipping filtering.\n",
            "Node fe7367c5-6f28-4097-b9b6-039cdea896cc does not have a summary. Skipping filtering.\n",
            "Node 94e9a139-b9ea-4ace-b63a-c44fd112e464 does not have a summary. Skipping filtering.\n",
            "Node ba7037aa-1c40-4d90-b7e1-d6f51a5ebd34 does not have a summary. Skipping filtering.\n",
            "Node 54cbbe6e-3e9b-46c1-b313-a5c744c2cf61 does not have a summary. Skipping filtering.\n",
            "Node ab6071c9-4774-46f1-89bb-2566f0382fb0 does not have a summary. Skipping filtering.\n",
            "Node eb9d6b3e-6061-467d-9639-71d71451c116 does not have a summary. Skipping filtering.\n",
            "Node 601cfbe1-553e-4c93-8ab5-1580ae124337 does not have a summary. Skipping filtering.\n",
            "Node 202356e4-809c-497f-984f-bbfaffa2fcc6 does not have a summary. Skipping filtering.\n",
            "Node e393060c-beee-4395-a058-ca223a8b083c does not have a summary. Skipping filtering.\n",
            "Node 6ded41de-77e2-417d-bde8-dfb56c06ac4e does not have a summary. Skipping filtering.\n",
            "Node e2af1681-2e57-4013-bc18-c60a72d850c2 does not have a summary. Skipping filtering.\n",
            "Node 7df86e01-e842-4d8a-9834-bfd5784d770d does not have a summary. Skipping filtering.\n",
            "Node 80b5db1a-164c-41bf-831e-4591ac1eefa9 does not have a summary. Skipping filtering.\n",
            "Node 8dfc9171-0127-472c-81da-eef351442242 does not have a summary. Skipping filtering.\n",
            "Node 28cb49bc-6bb0-41ef-a4eb-968a37493c03 does not have a summary. Skipping filtering.\n",
            "Node 0cbe717c-1853-46fe-9957-f7715be3be28 does not have a summary. Skipping filtering.\n",
            "Node a1bcc2e6-1ff9-47dd-a3d5-b6125d5e64ac does not have a summary. Skipping filtering.\n",
            "Node 6a478151-3f3a-4ffe-ac48-3f2dabd247a3 does not have a summary. Skipping filtering.\n",
            "Node f8a5cb64-e1c4-44a1-9975-515b851e4d24 does not have a summary. Skipping filtering.\n",
            "Node 91dd4e5e-676c-41e8-bc64-35dd7f21d184 does not have a summary. Skipping filtering.\n",
            "Node f6a52c1c-8794-4d06-b0c0-a87f6c3757da does not have a summary. Skipping filtering.\n",
            "Node 8b74235c-aa6b-435c-b577-74ee86fb5853 does not have a summary. Skipping filtering.\n",
            "Node 098dd6ba-776d-43fb-81d2-87eef52a2de7 does not have a summary. Skipping filtering.\n",
            "Node 810e3b51-8cd8-479d-b32f-3d99dd3cad24 does not have a summary. Skipping filtering.\n",
            "Node 75ba145e-6c40-4963-8441-9acfe491b5e7 does not have a summary. Skipping filtering.\n",
            "Node 33e6927d-181d-41c6-a3da-0cddc59738d0 does not have a summary. Skipping filtering.\n",
            "Node cd695b2d-68c1-4479-b8fd-f1c67fed737d does not have a summary. Skipping filtering.\n",
            "Node 9346e7e6-f7e1-4687-8db4-1d9caf476c85 does not have a summary. Skipping filtering.\n",
            "Node 51101a09-8200-44c0-8fbc-07559a4e1d0d does not have a summary. Skipping filtering.\n",
            "Node 07319fc4-c937-41bb-873c-87cbcd6990cc does not have a summary. Skipping filtering.\n",
            "Node 9112b813-51c0-416b-a7eb-2bb126864eab does not have a summary. Skipping filtering.\n",
            "Node 0d80783c-8549-4806-a130-364a8f9da656 does not have a summary. Skipping filtering.\n",
            "Node 95ba088d-8927-4162-8b1b-f0dd3d8f3d04 does not have a summary. Skipping filtering.\n",
            "Node 38378b79-264d-471a-aa0e-e786261656a8 does not have a summary. Skipping filtering.\n",
            "Node ae70c610-2e04-4a5a-a617-3c08ffe1e4bc does not have a summary. Skipping filtering.\n",
            "Node 3e664b39-195c-47c6-86c4-2bc1c83ccfd5 does not have a summary. Skipping filtering.\n",
            "Node 669cd528-fd65-485a-b8a5-691776ee1f36 does not have a summary. Skipping filtering.\n",
            "Node df8c9e61-538a-4373-a0ac-cbbf279b3317 does not have a summary. Skipping filtering.\n",
            "Node e65a528b-33c4-495c-b064-cf2458f2b056 does not have a summary. Skipping filtering.\n",
            "Node f421ad97-9b44-4b5c-ac8d-0582ce62f2fe does not have a summary. Skipping filtering.\n",
            "Node 0d1c44e1-625c-467d-aed6-1c13a44bad03 does not have a summary. Skipping filtering.\n",
            "Node 18b32159-0597-485a-bc4a-227201cb1e20 does not have a summary. Skipping filtering.\n",
            "Node cf5c4744-b65f-4280-ad88-26bbe50ed40d does not have a summary. Skipping filtering.\n",
            "Node 78d99cdb-46a8-40f1-ac31-4ed5ae797c6e does not have a summary. Skipping filtering.\n",
            "Node 367a1c30-163e-4dc3-9f41-0a69c74a6698 does not have a summary. Skipping filtering.\n",
            "Node 480739f2-e009-4829-8ba7-085bbf7f6ff7 does not have a summary. Skipping filtering.\n",
            "Node a748f20a-a474-440c-964b-814ec5f3bdaf does not have a summary. Skipping filtering.\n",
            "Node 71eb6f94-8525-4ac7-852d-b5c9bbc47c55 does not have a summary. Skipping filtering.\n",
            "Node 3a02b800-a123-46de-9e9e-29fdf613c223 does not have a summary. Skipping filtering.\n",
            "Node 749ea261-f86f-4c00-b6c4-b3e3083212da does not have a summary. Skipping filtering.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "832b532ae600400687fe2adecf4a2009",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying [EmbeddingExtractor, ThemesExtractor, NERExtractor]:   0%|          | 0/1615 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0d7be3f8aa1f4107840f8bca306ffb30",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying OverlapScoreBuilder:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b707be1bba604e02a97bdffdf325c952",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating Scenarios:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e4f576456f594f0a9901becbe7d11343",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating Samples:   0%|          | 0/50 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import copy\n",
        "\n",
        "kg_docs = copy.deepcopy(training_split_documents)\n",
        "\n",
        "for document in kg_docs:\n",
        "  id = document.metadata[\"id\"]\n",
        "  document.page_content = id+\"###\"+document.page_content\n",
        "\n",
        "kg_training_dataset = generator.generate_with_langchain_docs(kg_docs, testset_size=50, query_distribution=query_distribution)\n",
        "training_dataframe = kg_training_dataset.to_pandas()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7379c3e216a446c88e6a31dbf24b0b68",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying SummaryExtractor:   0%|          | 0/72 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d2b85b3098874835b22b15655f402e4a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying CustomNodeFilter:   0%|          | 0/91 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Node 61bf9e22-a29f-41c0-a325-4becfadfb294 does not have a summary. Skipping filtering.\n",
            "Node ce9482a2-97d6-429e-b902-1924ccfe35a4 does not have a summary. Skipping filtering.\n",
            "Node fda9e80f-7bb9-49cb-848d-4200689a446a does not have a summary. Skipping filtering.\n",
            "Node ce558062-d93f-45ea-8ebc-6a86688c1f92 does not have a summary. Skipping filtering.\n",
            "Node 55b874b7-e10b-43d2-b4a7-82e1cb23a237 does not have a summary. Skipping filtering.\n",
            "Node 87ac9130-ad01-45d6-a9c9-ce34b330a13a does not have a summary. Skipping filtering.\n",
            "Node f4b34e79-7ab2-43df-bb5b-a8d5e65da9ca does not have a summary. Skipping filtering.\n",
            "Node dffbc500-4dc6-430d-94d6-3aa2e84407fa does not have a summary. Skipping filtering.\n",
            "Node 0df59c03-b4b9-4c5e-bf93-77bc88418c14 does not have a summary. Skipping filtering.\n",
            "Node 7fe94bfe-5cf7-4d93-893e-6f98a90a4714 does not have a summary. Skipping filtering.\n",
            "Node 09520c08-5f36-4b8d-8119-84cf80962a15 does not have a summary. Skipping filtering.\n",
            "Node fffbc69b-8b3c-4e42-aea6-587bfad85cea does not have a summary. Skipping filtering.\n",
            "Node be8a8b13-8a2c-47e1-afcd-4100a29779a7 does not have a summary. Skipping filtering.\n",
            "Node bb29f69d-3e30-4049-aafc-f5b07698baf7 does not have a summary. Skipping filtering.\n",
            "Node 6fff9ea1-13d4-46c6-816a-2b41753a0592 does not have a summary. Skipping filtering.\n",
            "Node 19e3b0f4-41c1-4d9c-8f7c-3bac8c43cc48 does not have a summary. Skipping filtering.\n",
            "Node 62454859-190c-488c-9950-de43f809339c does not have a summary. Skipping filtering.\n",
            "Node c67374ac-9ede-432a-a9b8-ef8c6ccceb34 does not have a summary. Skipping filtering.\n",
            "Node 4cf36f79-862d-469c-b0bd-a792541157ea does not have a summary. Skipping filtering.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e04983b5d4f345a7b9d78431c0e3bbee",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying [EmbeddingExtractor, ThemesExtractor, NERExtractor]:   0%|          | 0/254 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0ba9a03f119f4e62b6eb425ae6c5ba8b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying OverlapScoreBuilder:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8bf722f5442d4fd9a5fe6133f5b6bf82",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating Scenarios:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7c5027c0dca74fb7922a346c1695db61",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating Samples:   0%|          | 0/50 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "kg_val_docs = copy.deepcopy(val_split_documents)\n",
        "\n",
        "for document in kg_val_docs:\n",
        "  id = document.metadata[\"id\"]\n",
        "  document.page_content = id+\"###\"+document.page_content\n",
        "\n",
        "kg_val_dataset = generator.generate_with_langchain_docs(kg_val_docs, testset_size=50, query_distribution=query_distribution)\n",
        "val_dataframe = kg_val_dataset.to_pandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fd4bd190a4d1454998b46627bd3560a6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying SummaryExtractor:   0%|          | 0/74 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bf6127127ef64436bc15a70dab7dae57",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying CustomNodeFilter:   0%|          | 0/93 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Node 420b7f38-1409-43b5-85b5-d5eb035fc750 does not have a summary. Skipping filtering.\n",
            "Node 5e09cfe0-55a3-41d3-9eed-8639a0f5cc56 does not have a summary. Skipping filtering.\n",
            "Node 75d56d2d-c02d-4794-961a-329cfa760a79 does not have a summary. Skipping filtering.\n",
            "Node 25a245ce-1040-4fb7-8d9f-b26023ec59ca does not have a summary. Skipping filtering.\n",
            "Node dffbe640-4b0b-4480-94c7-9f607757f327 does not have a summary. Skipping filtering.\n",
            "Node 6f34be65-caf5-42f9-82ba-b1ed0fba9dac does not have a summary. Skipping filtering.\n",
            "Node 01cf39bf-f35f-4068-b2ac-7387d4fef54c does not have a summary. Skipping filtering.\n",
            "Node efb1c802-f645-4a2e-ab62-a7c4f32b21d2 does not have a summary. Skipping filtering.\n",
            "Node f1232243-6d44-4d06-8b63-62b9042eb52a does not have a summary. Skipping filtering.\n",
            "Node ba458b2a-4ddb-4121-9f1e-606644be8c8c does not have a summary. Skipping filtering.\n",
            "Node 6713794e-13c4-48ec-8e45-7eb7da04d1d6 does not have a summary. Skipping filtering.\n",
            "Node 7b6f208e-dfe6-4830-b33c-8ade3530052a does not have a summary. Skipping filtering.\n",
            "Node 5f24d6a1-ecf1-4aa0-9a9b-e745d87fb0bd does not have a summary. Skipping filtering.\n",
            "Node 6e5d1b02-32ee-4888-b6e2-40a4df4a4584 does not have a summary. Skipping filtering.\n",
            "Node adb0dd57-c1ea-41cb-9926-2f10566bd0fd does not have a summary. Skipping filtering.\n",
            "Node c3bd742e-416e-428f-89d0-44ef927f522c does not have a summary. Skipping filtering.\n",
            "Node 049dbc4b-ef80-4de8-8245-af7ff596b107 does not have a summary. Skipping filtering.\n",
            "Node 36fd9556-549d-43a2-a4fd-470dd6835630 does not have a summary. Skipping filtering.\n",
            "Node 5c3d3fb1-23a7-42f1-8bfb-78462a480282 does not have a summary. Skipping filtering.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dea7458e392245a6ae5a6ba6088be35a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying [EmbeddingExtractor, ThemesExtractor, NERExtractor]:   0%|          | 0/260 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "79a7c554f812477caee51199a5179565",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying OverlapScoreBuilder:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "eb67325b681e4cc095dfaf1f0dd0dcd1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating Scenarios:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b9bc552ccfab4587b349347e23b183d6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating Samples:   0%|          | 0/50 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "kg_test_docs = copy.deepcopy(test_split_documents)\n",
        "\n",
        "for document in kg_test_docs:\n",
        "  id = document.metadata[\"id\"]\n",
        "  document.page_content = id+\"###\"+document.page_content\n",
        "\n",
        "kg_test_dataset = generator.generate_with_langchain_docs(kg_test_docs, testset_size=50, query_distribution=query_distribution)\n",
        "test_dataframe = kg_test_dataset.to_pandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "# \n",
        "def createKGDataSet(filename, dataframe, docs):\n",
        "  questions = {}\n",
        "  relevant_contexts = {}\n",
        "  corpus = {}\n",
        "\n",
        "  generated_questions = dataframe[\"user_input\"].to_list()\n",
        "\n",
        "  for i, question in enumerate(generated_questions):\n",
        "      q_id = str(uuid.uuid4())\n",
        "      questions[q_id] = question\n",
        "      reference_context = dataframe[\"reference_contexts\"][i]\n",
        "      doc_id = reference_context[0].split(\"###\")[0]\n",
        "      relevant_contexts[q_id] = [doc_id]\n",
        "\n",
        "  for document in docs:\n",
        "      document_id = document.metadata[\"id\"]\n",
        "      document_content = document.page_content.split(\"###\")[1]\n",
        "      corpus[document_id] = document_content\n",
        "\n",
        "  ds = {\n",
        "      \"questions\": questions,\n",
        "      \"relevant_contexts\": relevant_contexts,\n",
        "      \"corpus\": corpus\n",
        "  }\n",
        "\n",
        "  with open(filename, \"w\") as f:\n",
        "      json.dump(ds, f)\n",
        "\n",
        "\n",
        "# create the jsonl files and save to our data directory\n",
        "createKGDataSet(\"data_hard/kg_training_dataset.jsonl\", training_dataframe, kg_docs)\n",
        "createKGDataSet(\"data_hard/kg_val_dataset.jsonl\", val_dataframe, kg_val_docs)\n",
        "createKGDataSet(\"data_hard/kg_test_dataset.jsonl\", test_dataframe, kg_test_docs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vAwklqQCgVi-"
      },
      "source": [
        "## Task 4: Fine-tuning `snowflake-arctic-embed-l`\n",
        "\n",
        "Now that we have a dataset, let's grab a `sentence-transformers` Embeddings model!\n",
        "\n",
        "We'll be using Snowflake's [`snowflake-arctic-embed-l`](https://huggingface.co/Snowflake/snowflake-arctic-embed-l) as a base embeddings model.\n",
        "\n",
        "It is a well performing embeddings model by itself, but there's a lot of very specific domain terms and vocabulary in our courpus - so lets fine-tune it and see what that can do for us!\n",
        "\n",
        ">> NOTE: Skip installing dependencies if you are running this notebook locally."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AXzVHP3v1Cno",
        "outputId": "a9d6ca65-d355-460d-de89-7446a441512b"
      },
      "outputs": [],
      "source": [
        "#!pip install -qU sentence_transformers datasets pyarrow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G-PGsQB7Xo6V",
        "outputId": "8df58392-a82b-45f9-ce4e-b4155522e2c6"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "model_id = \"Snowflake/snowflake-arctic-embed-l\"\n",
        "model = SentenceTransformer(model_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ztG07iB8CFO"
      },
      "source": [
        "We'll grab some necessary imports from `sentence_transformers` and `torch`.\n",
        "\n",
        "> NOTE: PyTorch (`torch`) is a popular machine learning library - while we don't go very deep into PyTorch it's an incredibly powerful and interesting library! Please read more about it [here](https://pytorch.org/tutorials/beginner/basics/intro.html)!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "B-WbpuUWYFJr"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import Dataset\n",
        "from sentence_transformers import InputExample"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJtPPlck8HBE"
      },
      "source": [
        "We're using a toy batch size here to reflect the limited number of examples we have.\n",
        "\n",
        "> NOTE: It is typical to use a much larger batch size (~64+), hardware permitting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "8Lokhy6KYHAv"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "# train on subset of data for time\n",
        "SUBSET_SIZE = 100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-6DT8hc8PmT"
      },
      "source": [
        "Let's move our dataset into the expected format for training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "JJk37zQsYJ4P"
      },
      "outputs": [],
      "source": [
        "with open(\"data_hard/training_dataset.jsonl\", \"r\") as f:\n",
        "    t_ds = json.load(f)\n",
        "    n_corpus = t_ds[\"corpus\"]\n",
        "    n_queries = t_ds[\"questions\"]\n",
        "    n_relevant_docs = t_ds[\"relevant_contexts\"]\n",
        "\n",
        "# corpus = train_dataset['corpus']\n",
        "# queries = train_dataset['questions']\n",
        "# relevant_docs = train_dataset['relevant_contexts']\n",
        "\n",
        "naive_examples = []\n",
        "for query_id, query in n_queries.items():\n",
        "    doc_id = n_relevant_docs[query_id][0]\n",
        "    text = n_corpus[doc_id]\n",
        "    naive_example = InputExample(texts=[query, text])\n",
        "    naive_examples.append(naive_example)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OjFx7KHI8TL0"
      },
      "source": [
        "Now we can create a `torch` `DataLoader`!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "tiizmeIqZ_-w"
      },
      "outputs": [],
      "source": [
        "subset_naive_examples = naive_examples[:SUBSET_SIZE]\n",
        "# for naive\n",
        "naive_loader = DataLoader(\n",
        "    subset_naive_examples, batch_size=BATCH_SIZE\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_vA8rzlX8XbT"
      },
      "source": [
        "Next up, we'll prepare our loss function!\n",
        "\n",
        "Loss is an important part of training, fine-tuning, and more. If you want a deep dive on loss - you can check out our [event on loss!](https://www.youtube.com/watch?v=iB8FWR9aD5Q&t=8s).\n",
        "\n",
        "The core loss we're using today is called `MultipleNegativesRankingLoss` - you can find more information [here](https://github.com/UKPLab/sentence-transformers/blob/master/sentence_transformers/losses/MultipleNegativesRankingLoss.py).\n",
        "\n",
        "This is \"wrapped\" in `MatryoshkaLoss`, which you can read the implementation of [here](https://github.com/UKPLab/sentence-transformers/blob/master/sentence_transformers/losses/MatryoshkaLoss.py)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "Uga4nnBqlVeh"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers.losses import MatryoshkaLoss, MultipleNegativesRankingLoss\n",
        "\n",
        "matryoshka_dimensions = [768, 512, 256, 128, 64]\n",
        "inner_train_loss = MultipleNegativesRankingLoss(model)\n",
        "train_loss = MatryoshkaLoss(\n",
        "    model, inner_train_loss, matryoshka_dims=matryoshka_dimensions\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJG4fOm66PHI"
      },
      "source": [
        "##### 🏗️ Activity #2:\n",
        "\n",
        "Both of these losses sound \"cool\", but what are they - exactly - under the hood?\n",
        "\n",
        "Why are these losses specifically doing? Please write a short summary of each loss.\n",
        "\n",
        "> NOTE: This is a course focused on AI Engineering and the application of AI - looking for a hint? Try pasting the code (linked above) into ChatGPT/Claude to write the summary!\n",
        "\n",
        "- `MultipleNegativesRankingLoss` is a type of loss function that fundamentally uses a ranking algorithm in order to more closely associate semantically similar sentences, and further separate semantically dissimilar sentences. The ranking algorithm is done such that for each positive pair of similar sentences, there are multiple dissimilar, or negative pairs that should be ranked lower. Hence the name.\n",
        "\n",
        "- `MatryoshkaLoss` is a loss function designed to produce multiple dimension embeddings that are more-and-more granular hence the matryoshka doll reference. It accomplishes this by effectively being a wrapper for a \"inner loss function\" which is applied at multiple levels of a hierarchical embedding, with each level resulting in more granular, truncated dimension embedding. The dimensions are specified in matryoshka_dimensions. From the paper, it \"allows a single embedding to adapt to the computational constraints of downstream tasks\", while maintaining the fidelity of the truncated embeddings.\n",
        "\n",
        "- In the code, `MultipleNegativesRankingLoss` is the inner loss function for `MatryoshkaLoss`. The dimensions `[768, 512, 256, 128, 64]` are the levels of the embedding hierarchy where the MultipleNegativesRankingLoss is applied."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QKxRuXfH844c"
      },
      "source": [
        "Now we can set-up our evaluator.\n",
        "\n",
        "> NOTE: Due to the formatting of our dataset - this is all we have to do!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "f0hAFwUyaHQG"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers.evaluation import InformationRetrievalEvaluator\n",
        "\n",
        "with open(\"data_hard/val_dataset.jsonl\", \"r\") as f:\n",
        "    v_ds = json.load(f)\n",
        "    val_corpus = v_ds[\"corpus\"]\n",
        "    val_queries = v_ds[\"questions\"]\n",
        "    val_relevant_docs = v_ds[\"relevant_contexts\"]\n",
        "\n",
        "#for naive\n",
        "naive_evaluator = InformationRetrievalEvaluator(val_queries, val_corpus, val_relevant_docs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "BUILD KG LOADER AND EVALUATOR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [],
      "source": [
        "# build KG loader and evaluator\n",
        "\n",
        "with open(\"data_hard/kg_training_dataset.jsonl\", \"r\") as f:\n",
        "    kg_t_ds = json.load(f)\n",
        "    kg_corpus = kg_t_ds['corpus']\n",
        "    kg_queries = kg_t_ds['questions']\n",
        "    kg_relevant_docs = kg_t_ds['relevant_contexts']\n",
        "\n",
        "kg_examples = []\n",
        "for i, query in kg_queries.items():\n",
        "    doc_id = kg_relevant_docs[i][0]\n",
        "    text = kg_corpus[doc_id]\n",
        "    kg_example = InputExample(texts=[query, text])\n",
        "    kg_examples.append(kg_example)\n",
        "\n",
        "subset_kg_examples = kg_examples[:SUBSET_SIZE]\n",
        "kg_loader = DataLoader(\n",
        "    subset_kg_examples, batch_size=BATCH_SIZE\n",
        ")\n",
        "\n",
        "with open(\"data_hard/kg_val_dataset.jsonl\", \"r\") as f:\n",
        "    kg_v_ds = json.load(f)\n",
        "    kg_val_corpus = kg_v_ds['corpus']\n",
        "    kg_val_queries = kg_v_ds['questions']\n",
        "    kg_val_relevant_docs = kg_v_ds['relevant_contexts']\n",
        "\n",
        "kg_evaluator = InformationRetrievalEvaluator(kg_val_queries, kg_val_corpus, kg_val_relevant_docs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MYfap_ct8-bU"
      },
      "source": [
        "We'll train this model for 5 epochs, though you could increase this number if we had a significant amount more data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "svZG0pBHiQr6"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxitWoNX9DwW"
      },
      "source": [
        "It's training time!\n",
        "\n",
        "> NOTE: We're manually defining a warm-up period here - this is just to provide a smooth ramp into our training!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/dummy/dummy/runs/l5lp3dp4?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x33d271e80>"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import wandb\n",
        "wandb.init(mode=\"disabled\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "TRAIN WITH BOTH METHODS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 753,
          "referenced_widgets": [
            "0d3fc6edfdab4fe9aff8e805632eadad",
            "ebe8aa7a82124b57bce2d826c1dea0fa",
            "aa11c10b4234452d9430744ab89b59a2",
            "ca05cbcd72cb41d9856804ffb17b26cb",
            "cc2a33e9a7ac4c5699346fcbf53b7c95",
            "408f4dfce21a45cfad36047677ec8658",
            "ca5804644ef345c1b4f670fb7f088fe8",
            "2a872283afaa4a33a9bc3f9e57b3650b",
            "fe4d1052824c4ed29c38c5311087e650",
            "e283b1608c4d4266a03c57dc95aabb2e",
            "bfc4997e3bd94e66bebaa1ffdae1b99e"
          ]
        },
        "id": "aDhUHZY-iR09",
        "outputId": "6dbd9320-f7b9-46d6-b891-efdd12086631"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "22dff7d2e6cb45ee87998f459760b1f4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Computing widget examples:   0%|          | 0/1 [00:00<?, ?example/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [50/50 2:05:19, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Cosine Accuracy@1</th>\n",
              "      <th>Cosine Accuracy@3</th>\n",
              "      <th>Cosine Accuracy@5</th>\n",
              "      <th>Cosine Accuracy@10</th>\n",
              "      <th>Cosine Precision@1</th>\n",
              "      <th>Cosine Precision@3</th>\n",
              "      <th>Cosine Precision@5</th>\n",
              "      <th>Cosine Precision@10</th>\n",
              "      <th>Cosine Recall@1</th>\n",
              "      <th>Cosine Recall@3</th>\n",
              "      <th>Cosine Recall@5</th>\n",
              "      <th>Cosine Recall@10</th>\n",
              "      <th>Cosine Ndcg@10</th>\n",
              "      <th>Cosine Mrr@10</th>\n",
              "      <th>Cosine Map@100</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>No log</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.752747</td>\n",
              "      <td>0.884615</td>\n",
              "      <td>0.939560</td>\n",
              "      <td>0.978022</td>\n",
              "      <td>0.752747</td>\n",
              "      <td>0.294872</td>\n",
              "      <td>0.187912</td>\n",
              "      <td>0.097802</td>\n",
              "      <td>0.752747</td>\n",
              "      <td>0.884615</td>\n",
              "      <td>0.939560</td>\n",
              "      <td>0.978022</td>\n",
              "      <td>0.868374</td>\n",
              "      <td>0.832827</td>\n",
              "      <td>0.833937</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>No log</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.758242</td>\n",
              "      <td>0.906593</td>\n",
              "      <td>0.939560</td>\n",
              "      <td>0.967033</td>\n",
              "      <td>0.758242</td>\n",
              "      <td>0.302198</td>\n",
              "      <td>0.187912</td>\n",
              "      <td>0.096703</td>\n",
              "      <td>0.758242</td>\n",
              "      <td>0.906593</td>\n",
              "      <td>0.939560</td>\n",
              "      <td>0.967033</td>\n",
              "      <td>0.869751</td>\n",
              "      <td>0.837751</td>\n",
              "      <td>0.839842</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>No log</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.763736</td>\n",
              "      <td>0.901099</td>\n",
              "      <td>0.950549</td>\n",
              "      <td>0.967033</td>\n",
              "      <td>0.763736</td>\n",
              "      <td>0.300366</td>\n",
              "      <td>0.190110</td>\n",
              "      <td>0.096703</td>\n",
              "      <td>0.763736</td>\n",
              "      <td>0.901099</td>\n",
              "      <td>0.950549</td>\n",
              "      <td>0.967033</td>\n",
              "      <td>0.869945</td>\n",
              "      <td>0.838025</td>\n",
              "      <td>0.840238</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>No log</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.758242</td>\n",
              "      <td>0.906593</td>\n",
              "      <td>0.945055</td>\n",
              "      <td>0.972527</td>\n",
              "      <td>0.758242</td>\n",
              "      <td>0.302198</td>\n",
              "      <td>0.189011</td>\n",
              "      <td>0.097253</td>\n",
              "      <td>0.758242</td>\n",
              "      <td>0.906593</td>\n",
              "      <td>0.945055</td>\n",
              "      <td>0.972527</td>\n",
              "      <td>0.870583</td>\n",
              "      <td>0.837156</td>\n",
              "      <td>0.839162</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>No log</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.758242</td>\n",
              "      <td>0.912088</td>\n",
              "      <td>0.945055</td>\n",
              "      <td>0.972527</td>\n",
              "      <td>0.758242</td>\n",
              "      <td>0.304029</td>\n",
              "      <td>0.189011</td>\n",
              "      <td>0.097253</td>\n",
              "      <td>0.758242</td>\n",
              "      <td>0.912088</td>\n",
              "      <td>0.945055</td>\n",
              "      <td>0.972527</td>\n",
              "      <td>0.870936</td>\n",
              "      <td>0.837581</td>\n",
              "      <td>0.839587</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='25' max='25' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [25/25 02:57, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Cosine Accuracy@1</th>\n",
              "      <th>Cosine Accuracy@3</th>\n",
              "      <th>Cosine Accuracy@5</th>\n",
              "      <th>Cosine Accuracy@10</th>\n",
              "      <th>Cosine Precision@1</th>\n",
              "      <th>Cosine Precision@3</th>\n",
              "      <th>Cosine Precision@5</th>\n",
              "      <th>Cosine Precision@10</th>\n",
              "      <th>Cosine Recall@1</th>\n",
              "      <th>Cosine Recall@3</th>\n",
              "      <th>Cosine Recall@5</th>\n",
              "      <th>Cosine Recall@10</th>\n",
              "      <th>Cosine Ndcg@10</th>\n",
              "      <th>Cosine Mrr@10</th>\n",
              "      <th>Cosine Map@100</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>No log</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.620000</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>0.820000</td>\n",
              "      <td>0.860000</td>\n",
              "      <td>0.620000</td>\n",
              "      <td>0.233333</td>\n",
              "      <td>0.164000</td>\n",
              "      <td>0.086000</td>\n",
              "      <td>0.620000</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>0.820000</td>\n",
              "      <td>0.860000</td>\n",
              "      <td>0.726857</td>\n",
              "      <td>0.684833</td>\n",
              "      <td>0.691476</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>No log</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.620000</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>0.820000</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>0.620000</td>\n",
              "      <td>0.233333</td>\n",
              "      <td>0.164000</td>\n",
              "      <td>0.090000</td>\n",
              "      <td>0.620000</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>0.820000</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>0.743678</td>\n",
              "      <td>0.695468</td>\n",
              "      <td>0.699493</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>No log</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.620000</td>\n",
              "      <td>0.740000</td>\n",
              "      <td>0.860000</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>0.620000</td>\n",
              "      <td>0.246667</td>\n",
              "      <td>0.172000</td>\n",
              "      <td>0.090000</td>\n",
              "      <td>0.620000</td>\n",
              "      <td>0.740000</td>\n",
              "      <td>0.860000</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>0.753898</td>\n",
              "      <td>0.707333</td>\n",
              "      <td>0.711707</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>No log</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.660000</td>\n",
              "      <td>0.760000</td>\n",
              "      <td>0.880000</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>0.660000</td>\n",
              "      <td>0.253333</td>\n",
              "      <td>0.176000</td>\n",
              "      <td>0.090000</td>\n",
              "      <td>0.660000</td>\n",
              "      <td>0.760000</td>\n",
              "      <td>0.880000</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>0.772709</td>\n",
              "      <td>0.731857</td>\n",
              "      <td>0.736651</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>No log</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.660000</td>\n",
              "      <td>0.760000</td>\n",
              "      <td>0.880000</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>0.660000</td>\n",
              "      <td>0.253333</td>\n",
              "      <td>0.176000</td>\n",
              "      <td>0.090000</td>\n",
              "      <td>0.660000</td>\n",
              "      <td>0.760000</td>\n",
              "      <td>0.880000</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>0.773585</td>\n",
              "      <td>0.732857</td>\n",
              "      <td>0.737745</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "# make a reusable method since we are training with two different methods\n",
        "def trainMoustache(tuned_model_name, loader, evaluator):\n",
        "    warmup_steps = int(len(loader) * EPOCHS * 0.1)\n",
        "\n",
        "    model.fit(\n",
        "        train_objectives=[(loader, train_loss)],\n",
        "        epochs=EPOCHS,\n",
        "        warmup_steps=warmup_steps,\n",
        "        output_path=tuned_model_name,\n",
        "        show_progress_bar=True,\n",
        "        evaluator=evaluator,\n",
        "        evaluation_steps=50\n",
        "    )\n",
        "    model.push_to_hub(f\"{hf_username}/{tuned_model_name}\")\n",
        "\n",
        "trainMoustache(\"finetuned_arctic_ft_naive\", naive_loader, naive_evaluator)\n",
        "trainMoustache(\"finetuned_arctic_ft_kg\", kg_loader, kg_evaluator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "58699484312f460cb96ac44e3af14aa2",
            "d45a7d95e5b14a6f88d5798fec9c40a7",
            "b011a6ccf8e745c6be6f3a17b7d61dce",
            "1016780729b04ba489d488922173ddae",
            "9d34dac405fd40139d5dc04eecef55ed",
            "d6169577ffb341a69eb0175e301b6a44",
            "d4acc9a7aca04564bfaefe33de079394",
            "4e2c257232c3472697e03350de43cb30",
            "381c780ce17e4662981175400fb8a0f8",
            "878dc96f87dd45f389948a546db33e94",
            "006bf6f5ebaf400486a6b82610381db0",
            "9198dd0fa8f04aa7b75307aa2d513bfb",
            "59cd26ae53024fbd85431b6683cd119c",
            "4e7ccd97042c4fb9a201b6dc76762e04",
            "72ec09e2cbbf4788b1561abfcdd0819a",
            "fb1e19624fde4d3c8048ce00264d6056",
            "9638a0456e0c41b1b9b9757932f55c53",
            "18825dc83221412ab602830fc00db71b",
            "a6ea48a80c194d128959422368aa0e10",
            "9f4026c62c60493caa18c014ae414e65"
          ]
        },
        "id": "b3iwclvyRD8L",
        "outputId": "1471e984-9351-478c-de34-6eb32263fa30"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f4859a0dd92b4b819486081a066fec4a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()\n",
        "\n",
        "hf_username = \"don-unagi\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "e5c86e0e33264ed8b6325e44f9421653",
            "acf3991e5d644f468264f561b28b514a",
            "4a723c6a56e94309b2e3abe63f28aedc",
            "ef25768d3b0746b48c6d02e9bd151bf9",
            "cc1f0bc4a1a74568b9c74a7392a1568f",
            "95160a05de5b402b9bdb0bd2d099cd00",
            "cf376b0ea3544055b8867d7013526502",
            "869814ecd49e46f9a33dd53130e6953f",
            "cc7d460d3c5a4ac6a9b64929736d6598",
            "13e9bf583f6442d395334947379a280a",
            "1995b4d98fe044e38f1980d47033ca40"
          ]
        },
        "id": "Nqhf3zWa9AiJ",
        "outputId": "c601b2a8-f8e9-4d71-9c7b-8ea4999ff077"
      },
      "outputs": [],
      "source": [
        "#model.push_to_hub(f\"{hf_username}/legal-ft-2\")\n",
        "\n",
        "#just drag drop files to new model in HF with same names"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6bo0zW5k9Poq"
      },
      "source": [
        "## Task 5: Evaluating our Retriever\n",
        "\n",
        "Now that we have fine-tuned our retriever - let's see if it's worthwhile!\n",
        "\n",
        "We'll start with some basic imports."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "Vq-2oqU0wHFr"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_openai.embeddings import OpenAIEmbeddings\n",
        "from langchain_core.documents import Document"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5jD0qrIh9X8f"
      },
      "source": [
        "Now we'll define a function that will help us evaluate our retrieval process.\n",
        "\n",
        "> NOTE: We're assuming 1 correct document in a \"hit\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "0713_3cowX4q"
      },
      "outputs": [],
      "source": [
        "def evaluate_openai(\n",
        "    dataset,\n",
        "    embed_model,\n",
        "    top_k=5,\n",
        "    verbose=False,\n",
        "):\n",
        "  corpus = dataset['corpus']\n",
        "  questions = dataset['questions']\n",
        "  relevant_docs = dataset['relevant_contexts']\n",
        "  documents = [Document(page_content=content, metadata={\"id\": doc_id}) for doc_id, content in corpus.items()]\n",
        "  vectorstore = FAISS.from_documents(documents, embed_model)\n",
        "\n",
        "  retriever = vectorstore.as_retriever(search_kwargs={\"k\": top_k})\n",
        "\n",
        "  eval_results = []\n",
        "  for id, question in tqdm.tqdm(questions.items()):\n",
        "    retrieved_nodes = retriever.invoke(question)\n",
        "    retrieved_ids = [node.metadata[\"id\"] for node in retrieved_nodes]\n",
        "    expected_id = relevant_docs[id][0]\n",
        "    is_hit = expected_id in retrieved_ids\n",
        "    eval_results.append({\"id\": id, \"question\": question, \"expected_id\": expected_id, \"is_hit\": is_hit})\n",
        "\n",
        "  return eval_results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hOr49m4O9lxY"
      },
      "source": [
        "All that's left to do is evaluate, we'll evaluate our model against:\n",
        "\n",
        "1. OpenAI's closed source `text-embedding-3-small`\n",
        "2. The base non-fine-tuned version of `Snowflake/snowflake-arctic-embed-l`.\n",
        "\n",
        "Let's see how it stacks up!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ijaeYpf593IW"
      },
      "source": [
        "### `text-embedding-3-small`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kyY3PztaxnU3",
        "outputId": "5a1ec5e9-00fc-4140-d5b6-aa752dd4c9fa"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 186/186 [01:03<00:00,  2.92it/s]\n"
          ]
        }
      ],
      "source": [
        "te3_openai = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
        "te3_results = evaluate_openai(test_dataset, te3_openai)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "kkyW90TCxx_i"
      },
      "outputs": [],
      "source": [
        "te3_results_df = pd.DataFrame(te3_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MscVRdNCylJ-",
        "outputId": "275beff8-3c59-4063-8270-c01736b4ee05"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "np.float64(0.9247311827956989)"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "te3_hit_rate = te3_results_df[\"is_hit\"].mean()\n",
        "te3_hit_rate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Ra-mh0L96dQ"
      },
      "source": [
        "### `Snowflake/snowflake-arctic-embed-l` (base)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OEskxwvFypHe",
        "outputId": "a3aad8ce-48ef-4d8f-9ed0-122b1ec9a000"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 186/186 [00:07<00:00, 25.65it/s]\n"
          ]
        }
      ],
      "source": [
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "\n",
        "huggingface_embeddings = HuggingFaceEmbeddings(model_name=\"Snowflake/snowflake-arctic-embed-l\")\n",
        "arctic_embed_m_results = evaluate_openai(test_dataset, huggingface_embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "KlKgiXTWzMTg"
      },
      "outputs": [],
      "source": [
        "arctic_embed_m_results_df = pd.DataFrame(arctic_embed_m_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zV5vJWrJzOhc",
        "outputId": "30049be6-deb9-4ceb-dc13-24d7e125f131"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "np.float64(0.44623655913978494)"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "arctic_embed_m_hit_rate = arctic_embed_m_results_df[\"is_hit\"].mean()\n",
        "arctic_embed_m_hit_rate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lcR3-0s19_lu"
      },
      "source": [
        "### `Snowflake/snowflake-arctic-embed-l` (fine-tuned) - NAIVE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ilse1LduzP1i",
        "outputId": "292ab58f-7594-45fc-a5b8-1062cc553f66"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "817adc8ff78949d780a7c72ac23b027c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b7068d8981344bdda6bfff1ab887c7e9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/275 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "33e87e602d8346e0833c45d179d1a735",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md:   0%|          | 0.00/27.4k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8a5e1cfafd244f5d99163c573e1204f7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f61590f0a3114e80ac6daa1e4ae69b32",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/641 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "95b33b7d17644e75b449f18626228f00",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/1.34G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertModel were not initialized from the model checkpoint at don-unagi/finetuned_arctic_ft_naive and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4540b6de82ba46b0b380db308883c8d4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/1.41k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "63ed941d22034b8ba74cf9a3ad5d5615",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "33812141e76d4f088d17b1479174ae42",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/712k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9a7c8254df0344ddb6b24c2ca55a0ad5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/695 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dd6bdb24aa0f439cb7785c4d9f94f9ab",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "1_Pooling%2Fconfig.json:   0%|          | 0.00/297 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 186/186 [00:03<00:00, 47.92it/s]\n"
          ]
        }
      ],
      "source": [
        "finetune_naive_embeddings = HuggingFaceEmbeddings(model_name=\"don-unagi/finetuned_arctic_ft_naive\")\n",
        "finetune_naive_results = evaluate_openai(test_dataset, finetune_naive_embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "xxhZPqkNzZlh"
      },
      "outputs": [],
      "source": [
        "finetune_naive_results_df = pd.DataFrame(finetune_naive_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4thAK2BXzaj6",
        "outputId": "e890b5d1-86b7-4bfe-8ffe-a779a132e0c6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "np.float64(0.9247311827956989)"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "finetune_naive_hit_rate = finetune_naive_results_df[\"is_hit\"].mean()\n",
        "finetune_naive_hit_rate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### `Snowflake/snowflake-arctic-embed-l` (fine-tuned) - Knowledge Graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c52bc7b8061a42fe805ecb71ac0f843c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "215ed6009166416bbb275df07f779be2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/275 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b45a7833c67043cbb211a4cef300d7ee",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md:   0%|          | 0.00/30.0k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "84441ce66b744f73a2896f86cfa892f1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d897a17cbe154c4cbedf4b02f725794b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/641 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4053ec9d31af465bbf8c53d527e81ecc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/1.34G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertModel were not initialized from the model checkpoint at don-unagi/finetuned_arctic_ft_kg and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cfdc7ab9431040d3bee4e80ebeab24af",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/1.41k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "785f0b4e11f24b18bc9ac0cdf4537c76",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2aafdd45447d4fba9ad5e15baee535af",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/712k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "454dfdc6b64f43a5816b3ab60157a172",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/695 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d9a20902583f4740b192868e9453505a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "1_Pooling%2Fconfig.json:   0%|          | 0.00/297 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 186/186 [00:03<00:00, 47.34it/s]\n"
          ]
        }
      ],
      "source": [
        "finetune_kg_embeddings = HuggingFaceEmbeddings(model_name=\"don-unagi/finetuned_arctic_ft_kg\")\n",
        "finetune_kg_results = evaluate_openai(test_dataset, finetune_kg_embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [],
      "source": [
        "finetune_kg_results_df = pd.DataFrame(finetune_kg_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "np.float64(0.9247311827956989)"
            ]
          },
          "execution_count": 76,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "finetune_kg_hit_rate = finetune_kg_results_df[\"is_hit\"].mean()\n",
        "finetune_kg_hit_rate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iegFM209mBk3"
      },
      "source": [
        "## Task 1: Vibe Checking the RAG Pipeline\n",
        "\n",
        "We're going to use our RAG pipeline to vibe check on some common phrases now that we've modified it!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xzg0AA5krgR4"
      },
      "source": [
        "### Creating New Chunks\n",
        "\n",
        "In order to try and evaluate our system more fairly, let's create new chunks that we will use to create our Vector Store."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "KwQ2_LqNr0Tw"
      },
      "outputs": [],
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size = 600,\n",
        "    chunk_overlap  = 50,\n",
        "    length_function = len\n",
        ")\n",
        "\n",
        "training_documents = text_splitter.split_documents(text_loader.load())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gIdxahHXpP-c"
      },
      "source": [
        "### Base Chain\n",
        "\n",
        "We'll start by constructing our base chain, which will use the untrained retrieval model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bOsxIXpNpWC2"
      },
      "source": [
        "#### R - Retrieval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "azIGIKYfmNCT"
      },
      "outputs": [],
      "source": [
        "from langchain_community.vectorstores import FAISS\n",
        "\n",
        "base_vectorstore = FAISS.from_documents(training_documents, huggingface_embeddings)\n",
        "base_retriever = base_vectorstore.as_retriever(search_kwargs={\"k\": 6})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-1nVZ0KpX5N"
      },
      "source": [
        "#### A - Augmented"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "G10Fr-aKojeA"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "RAG_PROMPT = \"\"\"\\\n",
        "Given a provided context and a question, you must answer the question. If you do not know the answer, you must state that you do not know.\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "Question:\n",
        "{question}\n",
        "\n",
        "Answer:\n",
        "\"\"\"\n",
        "\n",
        "rag_prompt_template = ChatPromptTemplate.from_template(RAG_PROMPT)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Euq6RQEopZvD"
      },
      "source": [
        "#### G - Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "5-mfbbrypMHG"
      },
      "outputs": [],
      "source": [
        "rag_llm =  ChatOpenAI(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    temperature=0\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQ2p4mnUpbYY"
      },
      "source": [
        "#### RAG - LCEL RAG Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "ssuR-LaboyGq"
      },
      "outputs": [],
      "source": [
        "from operator import itemgetter\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough, RunnableParallel\n",
        "\n",
        "base_rag_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | base_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt_template | rag_llm | StrOutputParser(), \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "emm6WbB9pfKt",
        "outputId": "f0e0c83f-c617-493e-99ce-869061a315f3"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'base_rag_chain' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[67], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mbase_rag_chain\u001b[49m\u001b[38;5;241m.\u001b[39minvoke({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m\"\u001b[39m : \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHow do retirement accounts affect the financial aid process when applying for college grants through FAFSA?\u001b[39m\u001b[38;5;124m\"\u001b[39m})[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
            "\u001b[0;31mNameError\u001b[0m: name 'base_rag_chain' is not defined"
          ]
        }
      ],
      "source": [
        "base_rag_chain.invoke({\"question\" : \"How do retirement accounts affect the financial aid process when applying for college grants through FAFSA?\"})[\"response\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "mUOrd0OBprAq",
        "outputId": "0070d677-0bde-48be-a8a3-f0c53b9eee90"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'To determine how much you need for retirement, you can use the 4% Rule. This rule suggests that you should take your annual spending level and multiply it by 25. For example, if you spend $25,000 annually, you would need $625,000 to retire. Additionally, financial independence enthusiasts recommend multiplying your annual spending by somewhere between 20 and 30 to find your retirement number.'"
            ]
          },
          "execution_count": 84,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "base_rag_chain.invoke({\"question\" : \"How much do I need for retirement?\"})[\"response\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "OnfuFl59py7I",
        "outputId": "37480e29-17a6-40e2-fe8a-7eb6ea270569"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'The cost of beef per pound in MN is mentioned as $2.50/lb.'"
            ]
          },
          "execution_count": 123,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "base_rag_chain.invoke({\"question\" : \"What is the cost of beef per pound in MN??\"})[\"response\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "-NmqwHBDqTZ8",
        "outputId": "86d7b59a-97c6-4b65-805f-ae449e3b1a20"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"If retiring early is a goal of yours, you should prioritize the following:\\n\\n1. **Lifestyle Consideration**: Assess the lifestyle you want after retirement. Ensure that your saving efforts do not lead to a miserable existence before retirement, as it's important to enjoy your life now while planning for the future.\\n\\n2. **Savings and Frugality Skills**: Focus on building your savings and developing frugality skills. Worrying about whether you will have enough to retire should come after you have established a solid savings plan.\\n\\n3. **Investment**: Make it a priority to invest your savings, even if you feel you can't afford to. The reality is that you can't afford not to invest, as it can significantly impact your financial situation in retirement.\\n\\n4. **Flexibility in Retirement Plans**: Consider the possibility of working part-time during retirement or making lifestyle adjustments, such as living in a less expensive area or cutting back on discretionary spending, to reduce the amount you need to save.\\n\\n5. **Long-term Planning**: Think about how your early retirement fund will last until your old age retirement fund kicks in. This requires careful planning and realistic expectations about your financial needs.\\n\\nBy focusing on these priorities, you can create a more feasible plan for achieving early retirement.\""
            ]
          },
          "execution_count": 86,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "base_rag_chain.invoke({\"question\" : \"What priorities should I make if retiring early is a goal of mine?\"})[\"response\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SqNS0UJAp3lC"
      },
      "source": [
        "### NAIVE Fine-tuned Embedding Model\n",
        "\n",
        "Now let's rebuild our RAG chain with the Fine-tuned model - the only component we need to change is our `FAISS` vectorstore!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "ihO7tP6mqATy"
      },
      "outputs": [],
      "source": [
        "finetune_naive_vectorstore = FAISS.from_documents(training_documents, finetune_naive_embeddings)\n",
        "finetune_naive_retriever = finetune_naive_vectorstore.as_retriever(search_kwargs={\"k\": 6})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "1_cIFvWzqKGY"
      },
      "outputs": [],
      "source": [
        "finetune_naive_rag_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | finetune_naive_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt_template | rag_llm | StrOutputParser(), \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "OJmRHJF2qNgj",
        "outputId": "b99d4b58-8487-48ec-ee6c-8ea93f9b0192"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'To retire early, you can follow these steps:\\n\\n1. **Increase Your Savings Rate**: Aim to save a significant portion of your income, such as 50% or more. This can be achieved by living below your means and avoiding lifestyle inflation.\\n\\n2. **Invest Wisely**: Invest your savings in a diversified portfolio that can grow over time. Consider using retirement accounts that offer tax advantages.\\n\\n3. **Calculate Your Retirement Needs**: Use tools like retirement calculators to determine how much you need to save to sustain your desired lifestyle in retirement. The 4% rule is a common guideline, suggesting you can withdraw 4% of your retirement savings annually.\\n\\n4. **Consider Part-Time Work**: Some early retirees find that working part-time can help cover living expenses while allowing them to enjoy retirement.\\n\\n5. **Plan for Healthcare**: Ensure you have a plan for healthcare costs, as these can be significant before you qualify for Medicare.\\n\\n6. **Adjust Your Lifestyle**: Be prepared to make lifestyle changes to reduce expenses and increase savings.\\n\\nBy following these strategies, you can work towards achieving early retirement.'"
            ]
          },
          "execution_count": 89,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "finetune_naive_rag_chain.invoke({\"question\" : \"How do I retire early?\"})[\"response\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "EnK-c2ugqPPh",
        "outputId": "b8300e0a-1b51-48dd-93c3-254e0aa84e36"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'To determine how much you need for retirement, you can use the 4% Rule. This rule suggests that you should take your annual spending level and multiply it by 25. For example, if you spend $25,000 a year, you would need $625,000 to retire. Additionally, financial independence enthusiasts recommend taking your annual spending and multiplying it by somewhere between 20 and 30 to find your retirement number.'"
            ]
          },
          "execution_count": 90,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "finetune_naive_rag_chain.invoke({\"question\" : \"How much do I need for retirement?\"})[\"response\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "83hssg1AWozc",
        "outputId": "8d1ef134-7889-4379-a49b-6c0a476b7a1a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'To decrease your grocery bill, consider the following strategies:\\n\\n1. **Track Your Spending**: Keep a record of your grocery expenses to identify areas where you can cut back.\\n2. **Cook from Scratch**: Use basic ingredients that you buy in bulk to prepare meals at home, which can be more cost-effective than pre-packaged foods.\\n3. **Reduce Food Waste**: Pay attention to what you throw away and adjust your shopping habits accordingly to minimize waste.\\n4. **Buy Fresh Produce**: Allocate part of your budget for fresh fruits and vegetables, which can be healthier and more satisfying.\\n5. **Limit Eating Out**: Cut back on dining out to save money, as this can significantly impact your overall food expenses.\\n6. **Use Simple Cleaning Products**: Consider switching to inexpensive cleaning alternatives like white vinegar and baking soda, which can reduce costs associated with cleaning supplies.\\n\\nBy implementing these tips, you can effectively lower your grocery bill.'"
            ]
          },
          "execution_count": 91,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "finetune_naive_rag_chain.invoke({\"question\" : \"How do I decrease my grocery bill?\"})[\"response\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "rsHmGeFbqRET",
        "outputId": "1ab223c2-d2fc-46ac-8541-af038de3166d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'If retiring early is a goal of yours, you should prioritize the following:\\n\\n1. **Budgeting and Expense Management**: Start by assessing your current expenses and identify areas where you can cut back. Focus on living below your means to increase your savings rate.\\n\\n2. **Savings Rate**: Aim to save a significant portion of your income, ideally 50% or more if possible. This will help you build your nest egg more quickly.\\n\\n3. **Investment Strategy**: Invest your savings wisely to ensure they grow over time. Consider strategies like the 4% rule for withdrawals and factor in inflation.\\n\\n4. **Lifestyle Choices**: Be prepared to make lifestyle sacrifices now for a more comfortable retirement later. This may involve avoiding unnecessary expenses and not upgrading your lifestyle with raises.\\n\\n5. **Creativity and Engagement**: Cultivate interests and hobbies that you can pursue in retirement to avoid boredom and ensure a fulfilling life after work.\\n\\n6. **Long-term Planning**: Set a clear retirement goal, such as a specific nest egg amount, and create a plan to achieve it within your desired timeframe.\\n\\n7. **Flexibility**: Be open to adjusting your plans as needed, whether it’s changing your savings strategy or re-evaluating your retirement lifestyle.\\n\\nBy focusing on these priorities, you can work towards achieving your early retirement goal effectively.'"
            ]
          },
          "execution_count": 92,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "finetune_naive_rag_chain.invoke({\"question\" : \"What priorities should I make if retiring early is a goal of mine?\"})[\"response\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### KG Fine-tuned Embedding Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {},
      "outputs": [],
      "source": [
        "finetune_kg_vectorstore = FAISS.from_documents(training_documents, finetune_kg_embeddings)\n",
        "finetune_kg_retriever = finetune_kg_vectorstore.as_retriever(search_kwargs={\"k\": 6})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {},
      "outputs": [],
      "source": [
        "finetune_kg_rag_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | finetune_kg_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt_template | rag_llm | StrOutputParser(), \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'To retire early, you can follow these steps:\\n\\n1. **Set a Savings Goal**: Determine how much money you need to save to support your desired lifestyle in retirement. A common guideline is to aim for a nest egg that allows you to withdraw 4% annually.\\n\\n2. **Increase Your Savings Rate**: Aim to save a significant portion of your income. Some individuals save as much as 60% of their income, especially if they avoid lifestyle inflation (e.g., not spending raises on luxury items).\\n\\n3. **Invest Wisely**: Invest your savings in a diversified portfolio to grow your wealth over time. The timing of market conditions can impact your retirement, so aim to reach your retirement number during favorable market conditions.\\n\\n4. **Consider Alternative Income Sources**: Look for ways to generate additional income, such as side hustles or passive income streams, which can supplement your savings.\\n\\n5. **Plan for Healthcare and Other Expenses**: Factor in healthcare costs and other potential expenses in your retirement planning to ensure you have enough funds.\\n\\n6. **Use Retirement Calculators**: Utilize online retirement calculators to help you assess your savings and investment strategies.\\n\\nBy following these strategies, you can work towards achieving early retirement.'"
            ]
          },
          "execution_count": 102,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "finetune_kg_rag_chain.invoke({\"question\" : \"How do I retire early?\"})[\"response\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'To determine how much you need for retirement, you can use the 4% rule. This rule suggests that you should take your annual spending level and multiply it by 25. For example, if you plan to spend $25,000 per year, you would need $625,000 to retire. Financial Independence enthusiasts recommend a similar approach, suggesting you multiply your annual spending by somewhere between 20 and 30 to find your retirement number.'"
            ]
          },
          "execution_count": 101,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "finetune_kg_rag_chain.invoke({\"question\" : \"How much do I need for retirement?\"})[\"response\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'To decrease your grocery bill, consider the following strategies:\\n\\n1. **Stock Up on Basics**: Keep a supply of staple ingredients that you frequently use in your recipes. This allows you to cook more from scratch, which can be more cost-effective.\\n\\n2. **Buy in Bulk**: Purchase staples like beans and legumes in bulk to save money.\\n\\n3. **Focus on Fresh Produce**: By cooking from staples, you can allocate more of your budget to fresh fruits and vegetables, which are essential for a healthy diet.\\n\\n4. **Track Your Spending**: Monitor your grocery expenses to identify areas where you might be overspending or wasting food.\\n\\n5. **Reduce Waste**: Look at what you throw away and adjust your shopping habits accordingly to minimize waste.\\n\\n6. **Simplify Cleaning Supplies**: Consider switching to basic cleaning products like white vinegar and baking soda, which can save you money on cleaning supplies.\\n\\n7. **Shop Seasonally and Locally**: Buying seasonal and local produce can often be cheaper and fresher.\\n\\n8. **Optimize Food Prep and Storage**: Efficient food preparation and storage can help reduce spoilage and waste.\\n\\nBy implementing these strategies, you can effectively lower your grocery expenses.'"
            ]
          },
          "execution_count": 100,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "finetune_kg_rag_chain.invoke({\"question\" : \"How do I decrease my grocery bill?\"})[\"response\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'If retiring early is your goal, you should prioritize the following:\\n\\n1. **Savings Rate**: Aim to save a significant portion of your income, ideally 50% or more, to build your nest egg quickly.\\n\\n2. **Financial Independence**: Focus on reaching a point where your investments can generate enough income to cover your living expenses, often referred to as financial independence.\\n\\n3. **Budgeting**: Keep track of your expenses and create a budget that allows you to live below your means, which will help you save more.\\n\\n4. **Investment Strategy**: Invest wisely to grow your savings. Consider a diversified portfolio that balances risk and return.\\n\\n5. **Lifestyle Choices**: Make conscious choices about your lifestyle to reduce unnecessary expenses, which can help you save more for retirement.\\n\\n6. **Flexibility in Work**: Consider jobs or side gigs that you enjoy, which can provide income while allowing you to maintain a work-life balance.\\n\\n7. **Long-term Planning**: Set clear financial goals and timelines for when you want to retire, and regularly assess your progress towards those goals.\\n\\n8. **Emergency Fund**: Maintain an emergency fund to cover unexpected expenses, which can prevent you from dipping into your retirement savings.\\n\\nBy focusing on these priorities, you can create a solid plan for achieving early retirement.'"
            ]
          },
          "execution_count": 99,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "finetune_kg_rag_chain.invoke({\"question\" : \"What priorities should I make if retiring early is a goal of mine?\"})[\"response\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jDgD8seY_I3W"
      },
      "source": [
        "####❓Question #2:\n",
        "\n",
        "Which LCEL RAG Chain do you think answered the questions better, and why?\n",
        "\n",
        "- Just a few basic vibe checks, it seems like the finetuned models give fuller answers with better references to concepts from the blogs, but none of these do a bad job. Since these might be highly indexed topics, the base model is pretty good. But I would still prefer one of the tuned responses. Naive and KG seem pretty tied but we didn't really try very hard to make them fail. The vibes are too chill I guess. Let's leave it to RAGAS to bring the harsh vibes and evaluate more closely. Vibe checking only goes so far anyway. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WCbq1sZArIx4"
      },
      "source": [
        "## Task 2: RAGAS Evaluation\n",
        "\n",
        "It's great to have some idea of how our system is doing based on vibe-checks, but let's use RAGAS to provide more insight info. on how things are improving!\n",
        "\n",
        "> NOTE: Please recreate *exactly* the RAGAS process we used to evaluate RAG, baselining with the default retriever, and then comparing the new retriever. The includes the Synthetic Data Generation steps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "id": "jq880DtHk9pX"
      },
      "outputs": [],
      "source": [
        "### YOUR CODE HERE\n",
        "generator_llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4o\"))\n",
        "generator_embeddings = LangchainEmbeddingsWrapper(OpenAIEmbeddings())\n",
        "dataset_generator = TestsetGenerator(llm=generator_llm, embedding_model=generator_embeddings,persona_list=persona_list)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ea6dec2d41da41aea7a7c98cd7269859",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying HeadlinesExtractor:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "45bdaf970e564f408c99b9ee965ee94d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying HeadlineSplitter:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "788a6ac114c143c8a0f12a3ebe8226f2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying SummaryExtractor:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b03fc65087de47ea9bdcde11675c23df",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying CustomNodeFilter:   0%|          | 0/70 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b906832c949846c28a79330db35ce056",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying [EmbeddingExtractor, ThemesExtractor, NERExtractor]:   0%|          | 0/85 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3910c0fca3ff4225896b1c9926bd83d6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying [CosineSimilarityBuilder, OverlapScoreBuilder]:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1370842cdea24e6c8810544067ccfa60",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating Scenarios:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9480d3c22b134e7fbfcfd270acd69a97",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating Samples:   0%|          | 0/12 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "base_dataset = dataset_generator.generate_with_langchain_docs(text_loader.load(), testset_size=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'https://app.ragas.io/dashboard/alignment/testset/677eccf5-76b6-442a-b04a-9d2c4e1eeadf'"
            ]
          },
          "execution_count": 117,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "base_dataset.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "from uuid import uuid4\n",
        "\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass(\"LangChain API Key:\")\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = f\"AIM - SDG - {uuid4().hex[0:8]}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ragas import EvaluationDataset\n",
        "from ragas import evaluate\n",
        "from ragas.llms import LangchainLLMWrapper\n",
        "\n",
        "evaluation_dataset = EvaluationDataset.from_pandas(base_dataset.to_pandas())\n",
        "evaluator_llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4o\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ragas.metrics import LLMContextRecall, Faithfulness, FactualCorrectness, ResponseRelevancy, ContextEntityRecall, NoiseSensitivity\n",
        "from ragas import evaluate, RunConfig\n",
        "\n",
        "def evaluateDSWithRagChain(rag_chain):    \n",
        "    for test_row in base_dataset:\n",
        "        response = rag_chain.invoke({\"question\" : test_row.eval_sample.user_input})\n",
        "        test_row.eval_sample.response = response[\"response\"]\n",
        "        test_row.eval_sample.retrieved_contexts = [context.page_content for context in response[\"context\"]]\n",
        "            \n",
        "\n",
        "    evaluation_dataset = EvaluationDataset.from_pandas(base_dataset.to_pandas())\n",
        "    custom_run_config = RunConfig(timeout=360)\n",
        "\n",
        "    result = evaluate(\n",
        "        dataset=evaluation_dataset,\n",
        "        metrics=[LLMContextRecall(), Faithfulness(), FactualCorrectness(), ResponseRelevancy(), ContextEntityRecall(), NoiseSensitivity()],\n",
        "        llm=evaluator_llm,\n",
        "        run_config=custom_run_config\n",
        "    )\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d038f9230195438caedcb2f0c2f9a05b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/72 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "{'context_recall': 0.1647, 'faithfulness': 0.5224, 'factual_correctness': 0.2692, 'answer_relevancy': 0.6511, 'context_entity_recall': 0.1134, 'noise_sensitivity_relevant': 0.2495}"
            ]
          },
          "execution_count": 120,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "base_rag_chain_results = evaluateDSWithRagChain(base_rag_chain)\n",
        "base_rag_chain_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7bce57940cab4a1dbb7dd7593819922f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/72 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "{'context_recall': 0.2976, 'faithfulness': 0.4999, 'factual_correctness': 0.3450, 'answer_relevancy': 0.8059, 'context_entity_recall': 0.2327, 'noise_sensitivity_relevant': 0.1627}"
            ]
          },
          "execution_count": 121,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "finetune_naive_rag_chain_results = evaluateDSWithRagChain(finetune_naive_rag_chain)\n",
        "finetune_naive_rag_chain_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "160a768547d54ea8a87310f2cefac273",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/72 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Exception raised in Job[50]: TypeError(ufunc 'invert' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe'')\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'context_recall': 0.2579, 'faithfulness': 0.5012, 'factual_correctness': 0.3991, 'answer_relevancy': 0.8067, 'context_entity_recall': 0.2340, 'noise_sensitivity_relevant': 0.2125}"
            ]
          },
          "execution_count": 122,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "finetune_kg_rag_chain_results = evaluateDSWithRagChain(finetune_kg_rag_chain)\n",
        "finetune_kg_rag_chain_results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "\n",
        "| Metric | Base | Naive fine-tune | KG fine-tune |\n",
        "|--------|---------|---------|---------|\n",
        "| Context Recall | 0.1647 | 0.2976 | 0.2579 |\n",
        "| Faithfulness | 0.5224 | 0.4999 | 0.5012 |\n",
        "| Factual Correctness | 0.2692 | 0.3450 | 0.3991 |\n",
        "| Answer Relevancy | 0.6511 | 0.8059 | 0.8067 |\n",
        "| Context Entity Recall | 0.1134 | 0.2327 | 0.2340 |\n",
        "| Noise Sensitivity Relevant | 0.2495 | 0.1627 | 0.2125 |\n",
        "\n",
        "From the table, we can see that both fine-tuning methods (Naive and KG) improve the performance of the base model across most metrics. However, the improvements vary depending on the specific metric and the fine-tuning method used.\n",
        "\n",
        "\n",
        "1. Context Recall: This metric measures how well the model can recall the context when generating responses. The Naive fine-tuning method shows a significant improvement over the base model, while the KG fine-tuning method also improves but not as much as the Naive method.\n",
        "2. Faithfulness: This metric measures how well the model's responses stay true to the information in the context. Both fine-tuning methods show a slight decrease in performance compared to the base model.\n",
        "3. Factual Correctness: This metric measures the factual accuracy of the model's responses. Both fine-tuning methods improve the factual correctness, with the KG fine-tuning method showing the most significant improvement.\n",
        "4. Answer Relevancy: This metric measures how relevant the model's responses are to the input query. Both fine-tuning methods significantly improve the answer relevancy, with the KG fine-tuning method slightly outperforming the Naive method.\n",
        "5. Context Entity Recall: This metric measures how well the model can recall entities from the context in its responses. Both fine-tuning methods show a significant improvement over the base model, with the KG fine-tuning method slightly outperforming the Naive method.\n",
        "6. Noise Sensitivity Relevant: This metric measures how sensitive the model is to noise in the input query. The Naive fine-tuning method shows a significant improvement over the base model, while the KG fine-tuning method also improves but not as much as the Naive method.\n",
        "\n",
        "\n",
        "Some evaluation caveats:\n",
        "- the KG fine-tuning method was evaluated on the naive test data, so naive approach had a slight advantage. (we also had kg test data)\n",
        "- the Knowledge graph was primarily made up of single hop queries, if we were to use multihop test data, the KG evaluation would probably start to outperform the naive approach. Lesson here is that evaluation results can vary!\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "006bf6f5ebaf400486a6b82610381db0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0d3fc6edfdab4fe9aff8e805632eadad": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ebe8aa7a82124b57bce2d826c1dea0fa",
              "IPY_MODEL_aa11c10b4234452d9430744ab89b59a2",
              "IPY_MODEL_ca05cbcd72cb41d9856804ffb17b26cb"
            ],
            "layout": "IPY_MODEL_cc2a33e9a7ac4c5699346fcbf53b7c95"
          }
        },
        "1016780729b04ba489d488922173ddae": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "CheckboxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_9198dd0fa8f04aa7b75307aa2d513bfb",
            "style": "IPY_MODEL_59cd26ae53024fbd85431b6683cd119c",
            "value": true
          }
        },
        "13e9bf583f6442d395334947379a280a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18825dc83221412ab602830fc00db71b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a6ea48a80c194d128959422368aa0e10",
            "placeholder": "​",
            "style": "IPY_MODEL_9f4026c62c60493caa18c014ae414e65",
            "value": "Connecting..."
          }
        },
        "1995b4d98fe044e38f1980d47033ca40": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2a872283afaa4a33a9bc3f9e57b3650b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "381c780ce17e4662981175400fb8a0f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "408f4dfce21a45cfad36047677ec8658": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a723c6a56e94309b2e3abe63f28aedc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_869814ecd49e46f9a33dd53130e6953f",
            "max": 1336413848,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cc7d460d3c5a4ac6a9b64929736d6598",
            "value": 1336413848
          }
        },
        "4e2c257232c3472697e03350de43cb30": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e7ccd97042c4fb9a201b6dc76762e04": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "58699484312f460cb96ac44e3af14aa2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [],
            "layout": "IPY_MODEL_d4acc9a7aca04564bfaefe33de079394"
          }
        },
        "59cd26ae53024fbd85431b6683cd119c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "72ec09e2cbbf4788b1561abfcdd0819a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ButtonStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "869814ecd49e46f9a33dd53130e6953f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "878dc96f87dd45f389948a546db33e94": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9198dd0fa8f04aa7b75307aa2d513bfb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "95160a05de5b402b9bdb0bd2d099cd00": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9638a0456e0c41b1b9b9757932f55c53": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9d34dac405fd40139d5dc04eecef55ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ButtonModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_4e7ccd97042c4fb9a201b6dc76762e04",
            "style": "IPY_MODEL_72ec09e2cbbf4788b1561abfcdd0819a",
            "tooltip": ""
          }
        },
        "9f4026c62c60493caa18c014ae414e65": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a6ea48a80c194d128959422368aa0e10": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa11c10b4234452d9430744ab89b59a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2a872283afaa4a33a9bc3f9e57b3650b",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fe4d1052824c4ed29c38c5311087e650",
            "value": 1
          }
        },
        "acf3991e5d644f468264f561b28b514a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_95160a05de5b402b9bdb0bd2d099cd00",
            "placeholder": "​",
            "style": "IPY_MODEL_cf376b0ea3544055b8867d7013526502",
            "value": "model.safetensors: 100%"
          }
        },
        "b011a6ccf8e745c6be6f3a17b7d61dce": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "PasswordModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_878dc96f87dd45f389948a546db33e94",
            "placeholder": "​",
            "style": "IPY_MODEL_006bf6f5ebaf400486a6b82610381db0",
            "value": ""
          }
        },
        "bfc4997e3bd94e66bebaa1ffdae1b99e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ca05cbcd72cb41d9856804ffb17b26cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e283b1608c4d4266a03c57dc95aabb2e",
            "placeholder": "​",
            "style": "IPY_MODEL_bfc4997e3bd94e66bebaa1ffdae1b99e",
            "value": " 0/1 [00:00&lt;?, ?example/s]"
          }
        },
        "ca5804644ef345c1b4f670fb7f088fe8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cc1f0bc4a1a74568b9c74a7392a1568f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc2a33e9a7ac4c5699346fcbf53b7c95": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "cc7d460d3c5a4ac6a9b64929736d6598": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cf376b0ea3544055b8867d7013526502": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d45a7d95e5b14a6f88d5798fec9c40a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4e2c257232c3472697e03350de43cb30",
            "placeholder": "​",
            "style": "IPY_MODEL_381c780ce17e4662981175400fb8a0f8",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "d4acc9a7aca04564bfaefe33de079394": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "d6169577ffb341a69eb0175e301b6a44": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fb1e19624fde4d3c8048ce00264d6056",
            "placeholder": "​",
            "style": "IPY_MODEL_9638a0456e0c41b1b9b9757932f55c53",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "e283b1608c4d4266a03c57dc95aabb2e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5c86e0e33264ed8b6325e44f9421653": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_acf3991e5d644f468264f561b28b514a",
              "IPY_MODEL_4a723c6a56e94309b2e3abe63f28aedc",
              "IPY_MODEL_ef25768d3b0746b48c6d02e9bd151bf9"
            ],
            "layout": "IPY_MODEL_cc1f0bc4a1a74568b9c74a7392a1568f"
          }
        },
        "ebe8aa7a82124b57bce2d826c1dea0fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_408f4dfce21a45cfad36047677ec8658",
            "placeholder": "​",
            "style": "IPY_MODEL_ca5804644ef345c1b4f670fb7f088fe8",
            "value": "Computing widget examples:   0%"
          }
        },
        "ef25768d3b0746b48c6d02e9bd151bf9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_13e9bf583f6442d395334947379a280a",
            "placeholder": "​",
            "style": "IPY_MODEL_1995b4d98fe044e38f1980d47033ca40",
            "value": " 1.34G/1.34G [01:11&lt;00:00, 21.0MB/s]"
          }
        },
        "fb1e19624fde4d3c8048ce00264d6056": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe4d1052824c4ed29c38c5311087e650": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
